{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ramak\\\\OneDrive\\\\Desktop\\\\P2\\\\Image-Caption-Generator'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class TrainingConfig:\n",
    "    train_dir: Path\n",
    "    pkl_file: Path\n",
    "    csv_file_path: Path\n",
    "    saved_trained_model_dir: Path\n",
    "    epochs: int\n",
    "    batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \n",
      " True\n"
     ]
    }
   ],
   "source": [
    "from src.ImageCaptionGenerator.constants import *\n",
    "from src.ImageCaptionGenerator.utils.common import read_yaml, create_directory, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directory([self.config.main_dir])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        config = self.config.training\n",
    "        create_directory([config.model_dir])\n",
    "        # create_directory([config.train_dir])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            train_dir = config.train_dir,\n",
    "            pkl_file = config.pkl_file,\n",
    "            csv_file_path = config.csv_file_path,\n",
    "            saved_trained_model_dir = config.saved_trained_model_dir,\n",
    "            epochs = self.params.EPOCHS,\n",
    "            batch_size = self.params.BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-27 21:02:38,889: INFO: utils: NumExpr defaulting to 8 threads.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.ImageCaptionGenerator import logger\n",
    "import urllib.request as request\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "from glob import glob\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dropout, Embedding\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16\n",
    "import pickle\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self,config = TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def generator(self, image_dict, caption_dict, max_length, vocab_size):\n",
    "        while 1:\n",
    "            for i in range(0,len(caption_dict),self.config.batch_size):\n",
    "                caption = dict(list(caption_dict.items())[0+i: N+i])\n",
    "                X, y_in, y_out = self.create_sequences(image_dict,caption,max_length, vocab_size)\n",
    "                yield [X, y_in], y_out\n",
    "\n",
    "\n",
    "    def create_sequences(image, caption, max_length,vocab_size):\n",
    "    #n_samples = 0    \n",
    "        X,y_in,y_out = [],[],[]\n",
    "        \n",
    "        for k, v in caption.items():   \n",
    "            for i in range(1, len(v)):\n",
    "                X.append(image[k])\n",
    "        \n",
    "                in_seq= [v[:i]]\n",
    "                out_seq = v[i]\n",
    "        \n",
    "                in_seq = pad_sequences(in_seq, maxlen=max_length, padding='post', truncating='post')[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "        \n",
    "                y_in.append(in_seq)\n",
    "                y_out.append(out_seq)\n",
    "                \n",
    "        return np.array(X), np.array(y_in), np.array(y_out)\n",
    "\n",
    "\n",
    "    def training_model(self, vocab_size, max_length):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
